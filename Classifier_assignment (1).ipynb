{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fb0602",
   "metadata": {},
   "source": [
    "#### Name : Susmita Rani Saha , ID : B180305047        \n",
    "#### Name : Tanvir Ahammed Hridoy , ID : B180305020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a0903",
   "metadata": {},
   "source": [
    "# Classification Implementation :\n",
    "### Step 1 : importing all necessary libraries\n",
    "First of all we have to import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbb05d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfab47",
   "metadata": {},
   "source": [
    "### Step 2 : loading the CSV file here.\n",
    "Then load the csv file,so that we get a look at how to load and preprocess data. Now we just put the data file in the same directory as our Python file.The Pandas library has an easy way to load in data, read_csv():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ba2b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "    \n",
    "# It is a good idea to check and make sure the data is loaded as expected.\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057d426",
   "metadata": {},
   "source": [
    "### Step 3 : Preprocessing data\n",
    "Because the dataset has been prepared so well, we don't need to do a lot of preprocessing. Only we drop the \"ID\" column. As this isn't helpful we could drop it from the dataset using the drop() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86c661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67fc82",
   "metadata": {},
   "source": [
    "### Step 4 : Define features and labels\n",
    "We now need to define the features and labels. We can do this easily with Pandas by slicing the data table and choosing certain rows/columns with iloc().\n",
    "The slicing notation selects every row and every column except the last column (which is our label, the species)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d875cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas \".iloc\" expects row_indexer, column_indexer  \n",
    "X = data.iloc[:,:-1].values\n",
    "\n",
    "# Now let's tell the dataframe which column we want for the target/labels.  \n",
    "y = data['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06772c2b",
   "metadata": {},
   "source": [
    "### Step 5 : Split into train and test sets\n",
    "Now that we have the features and labels we want, we can split the data into training and testing sets using sklearn's handy feature train_test_split():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1a5b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test size specifies how much of the data you want to set aside for the testing set. \n",
    "# Random_state parameter is just a random seed we can use.\n",
    "# You can use it if you'd like to reproduce these specific results.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b988cb",
   "metadata": {},
   "source": [
    "### Step 6 : Print train sets\n",
    "We can print the results to be sure our data is being parsed as we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17a556ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3 2.7 4.9 1.8]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.  2.2 4.  1. ]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.1 3.8 1.5 0.3]]\n",
      "123     Iris-virginica\n",
      "40         Iris-setosa\n",
      "111     Iris-virginica\n",
      "97     Iris-versicolor\n",
      "86     Iris-versicolor\n",
      "            ...       \n",
      "37         Iris-setosa\n",
      "56     Iris-versicolor\n",
      "31         Iris-setosa\n",
      "72     Iris-versicolor\n",
      "19         Iris-setosa\n",
      "Name: Species, Length: 120, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)  \n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10268272",
   "metadata": {},
   "source": [
    "### Step 7 : instantiate the models\n",
    "Now we can instantiate the models. Follow this steps :\n",
    "First fit the classifiers,this train the model.\n",
    "Then predict and store the prediction in a variable, And print accuracy score, classification report and  confusion matrix.\n",
    "### i. Support Vector Machine (SVM)\n",
    "Support Vector Machines work by drawing a line between the different clusters of data points to group them into classes. Points on one side of the line will be one class and points on the other side belong to another class.\n",
    "\n",
    "The classifier will try to maximize the distance between the line it draws and the points on either side of it, to increase its confidence in which points belong to which class. When the testing points are plotted, the side of the line they fall on is the class they are put in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6dd03e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.91      0.91      0.91        11\n",
      " Iris-virginica       0.92      0.92      0.92        12\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.94      0.94      0.94        30\n",
      "   weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "SVC_model = SVC()\n",
    "SVC_model.fit(X_train, y_train)\n",
    "SVC_prediction = SVC_model.predict(X_test)\n",
    "print(accuracy_score(SVC_prediction, y_test))\n",
    "print(classification_report(y_test, SVC_prediction))\n",
    "print(confusion_matrix(SVC_prediction, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0811a13",
   "metadata": {},
   "source": [
    "### ii. Logistic Regression\n",
    "Logistic Regression outputs predictions about test data points on a binary scale, zero or one. If the value of something is 0.5 or above, it is classified as belonging to class 1, while below 0.5 if is classified as belonging to 0.\n",
    "\n",
    "Each of the features also has a label of only 0 or 1. Logistic regression is a linear classifier and therefore used when there is some sort of linear relationship between the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580cc113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.91      0.91      0.91        11\n",
      " Iris-virginica       0.92      0.92      0.92        12\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.94      0.94      0.94        30\n",
      "   weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  1 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My AsUs\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg_clf = LogisticRegression()\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "logreg_prediction = logreg_clf.predict(X_test)\n",
    "print(accuracy_score(logreg_prediction, y_test))\n",
    "print(classification_report(y_test, logreg_prediction))\n",
    "print(confusion_matrix(logreg_prediction, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a786670",
   "metadata": {},
   "source": [
    "### iii. K-Nearest Neighbors \n",
    "K-Nearest Neighbors operates by checking the distance from some test example to the known values of some training example. The group of data points/class that would give the smallest distance between the training points and the testing point is the class that is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d7311e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.92      1.00      0.96        11\n",
      " Iris-virginica       1.00      0.92      0.96        12\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.97      0.97      0.97        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "print(accuracy_score(knn_y_pred, y_test))\n",
    "print(classification_report(y_test, knn_y_pred))\n",
    "print(confusion_matrix(knn_y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba5ae9",
   "metadata": {},
   "source": [
    "### iv. Decision Tree\n",
    "A Decision Tree Classifier functions by breaking down a dataset into smaller and smaller subsets based on different criteria. Different sorting criteria will be used to divide the dataset, with the number of examples getting smaller with every division.\n",
    "\n",
    "Once the network has divided the data down to one example, the example will be put into a class that corresponds to a key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98079211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.83      0.91      0.87        11\n",
      " Iris-virginica       0.91      0.83      0.87        12\n",
      "\n",
      "       accuracy                           0.90        30\n",
      "      macro avg       0.91      0.91      0.91        30\n",
      "   weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "print(accuracy_score(dt_y_pred, y_test))\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "print(confusion_matrix(dt_y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d2cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
