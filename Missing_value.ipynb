{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c23e4c54",
   "metadata": {},
   "source": [
    "### Name : Susmita Rani Saha , ID : B-180305047\n",
    "### Name : Tanvir ahammed hridoy , ID : B-180305020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362f3e2",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4308301",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 1 : Import dataset and print\n",
    "first of all we have to import dataset which contain null or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fc5731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1   2   3    4     5      6   7  8\n",
      "0    6  148  72  35    0  33.6  0.627  50  1\n",
      "1    1   85  66  29    0  26.6  0.351  31  0\n",
      "2    8  183  64   0    0  23.3  0.672  32  1\n",
      "3    1   89  66  23   94  28.1  0.167  21  0\n",
      "4    0  137  40  35  168  43.1  2.288  33  1\n",
      "5    5  116  74   0    0  25.6  0.201  30  0\n",
      "6    3   78  50  32   88  31.0  0.248  26  1\n",
      "7   10  115   0   0    0  35.3  0.134  29  0\n",
      "8    2  197  70  45  543  30.5  0.158  53  1\n",
      "9    8  125  96   0    0   0.0  0.232  54  1\n",
      "10   4  110  92   0    0  37.6  0.191  30  0\n",
      "11  10  168  74   0    0  38.0  0.537  34  1\n",
      "12  10  139  80   0    0  27.1  1.441  57  0\n",
      "13   1  189  60  23  846  30.1  0.398  59  1\n",
      "14   5  166  72  19  175  25.8  0.587  51  1\n",
      "15   7  100   0   0    0  30.0  0.484  32  1\n",
      "16   0  118  84  47  230  45.8  0.551  31  1\n",
      "17   7  107  74   0    0  29.6  0.254  31  1\n",
      "18   1  103  30  38   83  43.3  0.183  33  0\n",
      "19   1  115  70  30   96  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and review rows\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# print the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6db0ab",
   "metadata": {},
   "source": [
    "# Show statistics values\n",
    "We can see that there are columns that have a minimum value of zero (0). On some columns, a value of zero does not make sense and indicates an invalid or missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbf2342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# summarize the dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1e212",
   "metadata": {},
   "source": [
    "# Check dimensions\n",
    "Looking at the datasetâ€™s dimensions as a measure of its size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49c84efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ecd61",
   "metadata": {},
   "source": [
    "# Step 2 : Check Missing value\n",
    "There are 2 ways for checking missing values.\n",
    "### Way 1 : compute the value = 0 in each column then print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcad8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8    500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_missing = (dataset[[0,1,2,3,4,5,6,7,8]] == 0).sum()\n",
    "# report the results\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef7b1c",
   "metadata": {},
   "source": [
    "### Way 2 : Replace 0 with nan, then call isnull() functions to mark all of the NaN values in the dataset as True and get a count of the missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3baddb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8    500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset[[0,1,2,3,4,5,6,7,8]] = dataset[[0,1,2,3,4,5,6,7,8]].replace(0, np.nan)\n",
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0f8c5",
   "metadata": {},
   "source": [
    "# Then check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef3097a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1     2     3      4     5      6   7    8\n",
      "0    6.0  148.0  72.0  35.0    NaN  33.6  0.627  50  1.0\n",
      "1    1.0   85.0  66.0  29.0    NaN  26.6  0.351  31  NaN\n",
      "2    8.0  183.0  64.0   NaN    NaN  23.3  0.672  32  1.0\n",
      "3    1.0   89.0  66.0  23.0   94.0  28.1  0.167  21  NaN\n",
      "4    NaN  137.0  40.0  35.0  168.0  43.1  2.288  33  1.0\n",
      "5    5.0  116.0  74.0   NaN    NaN  25.6  0.201  30  NaN\n",
      "6    3.0   78.0  50.0  32.0   88.0  31.0  0.248  26  1.0\n",
      "7   10.0  115.0   NaN   NaN    NaN  35.3  0.134  29  NaN\n",
      "8    2.0  197.0  70.0  45.0  543.0  30.5  0.158  53  1.0\n",
      "9    8.0  125.0  96.0   NaN    NaN   NaN  0.232  54  1.0\n",
      "10   4.0  110.0  92.0   NaN    NaN  37.6  0.191  30  NaN\n",
      "11  10.0  168.0  74.0   NaN    NaN  38.0  0.537  34  1.0\n",
      "12  10.0  139.0  80.0   NaN    NaN  27.1  1.441  57  NaN\n",
      "13   1.0  189.0  60.0  23.0  846.0  30.1  0.398  59  1.0\n",
      "14   5.0  166.0  72.0  19.0  175.0  25.8  0.587  51  1.0\n",
      "15   7.0  100.0   NaN   NaN    NaN  30.0  0.484  32  1.0\n",
      "16   NaN  118.0  84.0  47.0  230.0  45.8  0.551  31  1.0\n",
      "17   7.0  107.0  74.0   NaN    NaN  29.6  0.254  31  1.0\n",
      "18   1.0  103.0  30.0  38.0   83.0  43.3  0.183  33  NaN\n",
      "19   1.0  115.0  70.0  30.0   96.0  34.6  0.529  32  1.0\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd1a51",
   "metadata": {},
   "source": [
    "# Step 3 : Missing Values Causes Problems checking\n",
    "apply a model on the dataset which contain missing values. It causes problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2942d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3 fits failed out of a total of 3.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\ana\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 544, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"E:\\ana\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"E:\\ana\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"E:\\ana\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"E:\\ana\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# example where missing values cause errors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436694c9",
   "metadata": {},
   "source": [
    "# Step 4 : Handeling missing values\n",
    "## way 1: Drop missing values\n",
    "We can drop missing values in two ways. We can use one of them. It use dropna() function.\n",
    "### i) Drop Rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd0c6b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(111, 9)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any missing value\n",
    "print(dataset.shape)\n",
    "dataset.dropna(axis=0,inplace=True)\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32e2ba",
   "metadata": {},
   "source": [
    "### ii) Drops Columns with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d60964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 9)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with any missing value\n",
    "dataset.dropna(axis=1,inplace=True)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38767228",
   "metadata": {},
   "source": [
    "# Again apply model\n",
    "After removing missing values the model can perform perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b66d92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3114ad1",
   "metadata": {},
   "source": [
    "# Way 2 : Fill another values\n",
    "We can also replace missing values with mean, mode, median values, instead of droping missing values. For this we use fillna() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "958139fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8    500\n",
      "dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "dataset[[0,1,2,3,4,5,6,7,8]] = dataset[[0,1,2,3,4,5,6,7,8]].replace(0, np.nan)\n",
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d06b8",
   "metadata": {},
   "source": [
    "# way 3 : Replace another values using simpleimpute class\n",
    "We can also uses the SimpleImputer class to replace missing values with the mean of each column then prints the number of NaN values in the transformed matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57b2e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    111\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8    500\n",
      "dtype: int64\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "dataset[[0,1,2,3,4,5,6,7,8]] = dataset[[0,1,2,3,4,5,6,7,8]].replace(0, np.nan)\n",
    "# count the number of nan values in each column\n",
    "print(dataset.isnull().sum())\n",
    "# retrieve the numpy array\n",
    "values = dataset.values\n",
    "# define the imputer\n",
    "imputer = SimpleImputer(missing_values=nan, strategy='mean')\n",
    "# transform the dataset\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "# count the number of NaN values in each column\n",
    "print('Missing: %d' % np.isnan(transformed_values).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
